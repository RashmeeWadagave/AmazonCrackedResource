{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoqJkkgt1qk7"
      },
      "source": [
        "# Docling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cW90jnKh1yug",
        "outputId": "e5d0a283-51f5-4478-fc9c-bceef223f24b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N80q7I-V1qk9"
      },
      "source": [
        "[Docling](https://github.com/DS4SD/docling) parses PDF, DOCX, PPTX, HTML, and other formats into a rich unified representation including document layout, tables etc., making them ready for generative AI workflows like RAG.\n",
        "\n",
        "This integration provides Docling's capabilities via the `DoclingLoader` document loader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUQFRucy1qk-"
      },
      "source": [
        "## Overview\n",
        "\n",
        "<!--\n",
        "### Integration details\n",
        "\n",
        "| Class | Package | Local | Serializable | JS support|\n",
        "| :--- | :--- | :---: | :---: |  :---: |\n",
        "| langchain_docling.DoclingLoader | langchain-docling | ✅ | ❌ | ❌ |\n",
        "\n",
        "### Loader features\n",
        "| Source | Document Lazy Loading | Native Async Support\n",
        "| :---: | :---: | :---: |\n",
        "| DoclingLoader | ✅ | ❌ |\n",
        " -->\n",
        "\n",
        "The presented `DoclingLoader` component enables you to:\n",
        "- use various document types in your LLM applications with ease and speed, and\n",
        "- leverage Docling's rich format for advanced, document-native grounding.\n",
        "\n",
        "`DoclingLoader` supports two different export modes:\n",
        "- `ExportType.DOC_CHUNKS` (default): if you want to have each input document chunked and\n",
        "  to then capture each individual chunk as a separate LangChain Document downstream, or\n",
        "- `ExportType.MARKDOWN`: if you want to capture each input document as a separate\n",
        "  LangChain Document\n",
        "\n",
        "The example allows exploring both modes via parameter `EXPORT_TYPE`; depending on the\n",
        "value set, the example pipeline is then set up accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7lvVgti1qlA"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_qvL2CzD1qlA",
        "outputId": "1f309652-4e2d-49cd-fff4-5b5abc2bcf36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain-docling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbdQVLSc1qlD"
      },
      "source": [
        "> For best conversion speed, use GPU acceleration whenever available; e.g. if running on Colab, use a GPU-enabled runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZtbRnOH1qlD"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIF9KnfZ1qlE"
      },
      "source": [
        "Basic initialization looks as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UDj1WDi41qlE"
      },
      "outputs": [],
      "source": [
        "from langchain_docling import DoclingLoader\n",
        "\n",
        "FILE_PATH = \"/content/drive/MyDrive/TDS/edited-SP2200852_-_ICG1_TDS_-_Custo__NewDev__Architecture_and_External_Livery.pdf\"\n",
        "\n",
        "#loader = DoclingLoader(file_path=FILE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_1HBffB1qlE"
      },
      "source": [
        "For advanced usage, `DoclingLoader` has the following parameters:\n",
        "- `file_path`: source as single str (URL or local file) or iterable thereof\n",
        "- `converter` (optional): any specific Docling converter instance to use\n",
        "- `convert_kwargs` (optional): any specific kwargs for conversion execution\n",
        "- `export_type` (optional): export mode to use: `ExportType.DOC_CHUNKS` (default) or\n",
        "    `ExportType.MARKDOWN`\n",
        "- `md_export_kwargs` (optional): any specific Markdown export kwargs (for Markdown mode)\n",
        "- `chunker` (optional): any specific Docling chunker instance to use (for doc-chunk\n",
        "    mode)\n",
        "- `meta_extractor` (optional): any specific metadata extractor to use\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install deps\n",
        "!pip install pandas openpyxl\n",
        "!pip install -qU langchain-docling"
      ],
      "metadata": {
        "id": "UkbkkyAo2y_2",
        "outputId": "93b87ae8-ee9f-42e2-f30b-3d9ec48ec207",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_docling import DoclingLoader\n",
        "from langchain_docling.loader import ExportType\n",
        "\n",
        "FILE_PATH = \"/content/drive/MyDrive/TDS/edited-SP2200852_-_ICG1_TDS_-_Custo__NewDev__Architecture_and_External_Livery.pdf\"\n",
        "\n",
        "loader = DoclingLoader(\n",
        "    file_path=FILE_PATH,\n",
        "    export_type=ExportType.MARKDOWN\n",
        ")\n",
        "\n",
        "docs = loader.load()  # or use loader.lazy_load()\n",
        "print(f\"Loaded {len(docs)} document(s) as Markdown\")\n",
        "print(\"---- Markdown Preview ----\\n\")\n",
        "print(docs[0].page_content[:1000])"
      ],
      "metadata": {
        "id": "yK2CKJ2D3Lpw",
        "outputId": "a4f32a10-da36-42ce-ba3b-1bc658d98bf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the first extracted doc as markdown\n",
        "with open(\"extracted_doc.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(docs[0].page_content)\n",
        "\n",
        "print(\"✅ Markdown saved as extracted_doc.md\")"
      ],
      "metadata": {
        "id": "w449WdMn3i8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# ============================\n",
        "# 1. Load Markdown file\n",
        "# ============================\n",
        "markdown_path = \"/content/deliverables.md\"   # change this to your markdown path\n",
        "with open(markdown_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    md_text = f.read()\n",
        "\n",
        "# ============================\n",
        "# 2. Regex to find JSON-like blocks\n",
        "# ============================\n",
        "pattern = re.compile(r'\\{[^}]+\\}', re.DOTALL)\n",
        "matches = pattern.findall(md_text)\n",
        "\n",
        "records = []\n",
        "for match in matches:\n",
        "    try:\n",
        "        # Convert single JSON object\n",
        "        obj = json.loads(match.replace(\"“\",\"\\\"\").replace(\"”\",\"\\\"\"))\n",
        "        records.append(obj)\n",
        "    except:\n",
        "        # Try to clean keys manually if JSON-like\n",
        "        obj = {}\n",
        "        for line in match.splitlines():\n",
        "            if \":\" in line:\n",
        "                key, val = line.split(\":\",1)\n",
        "                key = key.strip().strip('\"').strip()\n",
        "                val = val.strip().strip('\",')\n",
        "                obj[key] = val\n",
        "        records.append(obj)\n",
        "\n",
        "# ============================\n",
        "# 3. Normalize & enforce schema\n",
        "# ============================\n",
        "df = pd.DataFrame(records)\n",
        "\n",
        "expected_cols = [\"deliverable_reference\", \"description\", \"tools_formats\", \"batch_no\", \"section_id\", \"section_title\"]\n",
        "for col in expected_cols:\n",
        "    if col not in df.columns:\n",
        "        df[col] = None\n",
        "\n",
        "df = df[expected_cols]   # reorder columns\n",
        "\n",
        "# ============================\n",
        "# 4. Save to Excel\n",
        "# ============================\n",
        "excel_path = \"/content/deliverables.xlsx\"\n",
        "df.to_excel(excel_path, index=False)\n",
        "\n",
        "print(f\"✅ Deliverables exported to {excel_path}\")"
      ],
      "metadata": {
        "id": "XdGgWdDg22e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inBhmpbZ1qlF"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzLLzUt31qlG",
        "outputId": "04221394-dc63-47fb-e2fd-6fb107dcf3d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oK5Un_C01qlH"
      },
      "source": [
        "> Note: a message saying `\"Token indices sequence length is longer than the specified\n",
        "maximum sequence length...\"` can be ignored in this case — more details\n",
        "[here](https://github.com/DS4SD/docling-core/issues/119#issuecomment-2577418826)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8EQ47Fc1qlH"
      },
      "source": [
        "Inspecting some sample docs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB5rcXtK1qlH",
        "outputId": "638bd4c7-536d-430a-d945-efbb886e4be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- d.page_content='arXiv:2408.09869v5  [cs.CL]  9 Dec 2024'\n",
            "- d.page_content='Docling Technical Report\\nVersion 1.0\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\\nAI4K Group, IBM Research R¨uschlikon, Switzerland'\n",
            "- d.page_content='Abstract\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n"
          ]
        }
      ],
      "source": [
        "for d in docs[:3]:\n",
        "    print(f\"- {d.page_content=}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcKBaRdT1qlI"
      },
      "source": [
        "## Lazy Load\n",
        "\n",
        "Documents can also be loaded in a lazy fashion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX8JaQzN1qlI"
      },
      "outputs": [],
      "source": [
        "doc_iter = loader.lazy_load()\n",
        "for doc in doc_iter:\n",
        "    pass  # you can operate on `doc` here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfL3lMHE1qlI"
      },
      "source": [
        "## End-to-end Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FM6C-_vY1qlI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# https://github.com/huggingface/transformers/issues/5486:\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCnd8Rp91qlJ"
      },
      "source": [
        "\n",
        "> - The following example pipeline uses HuggingFace's Inference API; for increased LLM quota, token can be provided via env var `HF_TOKEN`.\n",
        "> - Dependencies for this pipeline can be installed as shown below (`--no-warn-conflicts` meant for Colab's pre-populated Python env; feel free to remove for stricter usage):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br66j8ol1qlJ",
        "outputId": "7eb66f4a-b3cc-4761-ef4e-0671f5c39245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q --progress-bar off --no-warn-conflicts langchain-core langchain-huggingface langchain-milvus langchain python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcrJ6PL61qlJ"
      },
      "source": [
        "Defining the pipeline parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waYpAM4Y1qlK"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from tempfile import mkdtemp\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_docling.loader import ExportType\n",
        "\n",
        "\n",
        "def _get_env_from_colab_or_os(key):\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "\n",
        "        try:\n",
        "            return userdata.get(key)\n",
        "        except userdata.SecretNotFoundError:\n",
        "            pass\n",
        "    except ImportError:\n",
        "        pass\n",
        "    return os.getenv(key)\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "HF_TOKEN = _get_env_from_colab_or_os(\"HF_TOKEN\")\n",
        "FILE_PATH = [\"https://arxiv.org/pdf/2408.09869\"]  # Docling Technical Report\n",
        "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "GEN_MODEL_ID = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
        "QUESTION = \"Which are the main AI models in Docling?\"\n",
        "PROMPT = PromptTemplate.from_template(\n",
        "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {input}\\nAnswer:\\n\",\n",
        ")\n",
        "TOP_K = 3\n",
        "MILVUS_URI = str(Path(mkdtemp()) / \"docling.db\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STCdQ1-01qlK"
      },
      "source": [
        "Now we can instantiate our loader and load documents:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLhjsQHs1qlL",
        "outputId": "38447cff-af5a-40c7-b6b0-a13fc708cef9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "from docling.chunking import HybridChunker\n",
        "from langchain_docling import DoclingLoader\n",
        "\n",
        "loader = DoclingLoader(\n",
        "    file_path=FILE_PATH,\n",
        "    export_type=EXPORT_TYPE,\n",
        "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
        ")\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHsPpMu1qlL"
      },
      "source": [
        "Determining the splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvr_i8VK1qlL"
      },
      "outputs": [],
      "source": [
        "if EXPORT_TYPE == ExportType.DOC_CHUNKS:\n",
        "    splits = docs\n",
        "elif EXPORT_TYPE == ExportType.MARKDOWN:\n",
        "    from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "    splitter = MarkdownHeaderTextSplitter(\n",
        "        headers_to_split_on=[\n",
        "            (\"#\", \"Header_1\"),\n",
        "            (\"##\", \"Header_2\"),\n",
        "            (\"###\", \"Header_3\"),\n",
        "        ],\n",
        "    )\n",
        "    splits = [split for doc in docs for split in splitter.split_text(doc.page_content)]\n",
        "else:\n",
        "    raise ValueError(f\"Unexpected export type: {EXPORT_TYPE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXUGhxD31qlM"
      },
      "source": [
        "Inspecting some sample splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD-Ic_DS1qlM",
        "outputId": "014c4792-22a4-499b-a83b-1d833ad0af9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- d.page_content='arXiv:2408.09869v5  [cs.CL]  9 Dec 2024'\n",
            "- d.page_content='Docling Technical Report\\nVersion 1.0\\nChristoph Auer Maksym Lysak Ahmed Nassar Michele Dolfi Nikolaos Livathinos Panos Vagenas Cesar Berrospi Ramis Matteo Omenetti Fabian Lindlbauer Kasper Dinkla Lokesh Mishra Yusik Kim Shubham Gupta Rafael Teixeira de Lima Valery Weber Lucas Morin Ingmar Meijer Viktor Kuropiatnyk Peter W. J. Staar\\nAI4K Group, IBM Research R¨uschlikon, Switzerland'\n",
            "- d.page_content='Abstract\\nThis technical report introduces Docling , an easy to use, self-contained, MITlicensed open-source package for PDF document conversion. It is powered by state-of-the-art specialized AI models for layout analysis (DocLayNet) and table structure recognition (TableFormer), and runs efficiently on commodity hardware in a small resource budget. The code interface allows for easy extensibility and addition of new features and models.'\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "for d in splits[:3]:\n",
        "    print(f\"- {d.page_content=}\")\n",
        "print(\"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcAz-3vb1qlN"
      },
      "source": [
        "### Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPO2Rymt1qlN"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from tempfile import mkdtemp\n",
        "\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_milvus import Milvus\n",
        "\n",
        "embedding = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
        "\n",
        "milvus_uri = str(Path(mkdtemp()) / \"docling.db\")  # or set as needed\n",
        "vectorstore = Milvus.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    collection_name=\"docling_demo\",\n",
        "    connection_args={\"uri\": milvus_uri},\n",
        "    index_params={\"index_type\": \"FLAT\"},\n",
        "    drop_old=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L2kgDgK1qlN"
      },
      "source": [
        "### RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfjLNi9F1qlO"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": TOP_K})\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=GEN_MODEL_ID,\n",
        "    huggingfacehub_api_token=HF_TOKEN,\n",
        "    task=\"text-generation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV2FnWc01qlP"
      },
      "outputs": [],
      "source": [
        "def clip_text(text, threshold=100):\n",
        "    return f\"{text[:threshold]}...\" if len(text) > threshold else text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sx0LxmtV1qlP",
        "outputId": "276352d8-5ed2-4cbd-c06e-b7dfc2e2dad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question:\n",
            "Which are the main AI models in Docling?\n",
            "\n",
            "Answer:\n",
            "The main AI models in Docling are a layout analysis model, which is an accurate object-detector for page elements, and TableFormer, a state-of-the-art table structure recognition model.\n",
            "\n",
            "Source 1:\n",
            "  text: \"3.2 AI models\\nAs part of Docling, we initially release two highly capable AI models to the open-source community, which have been developed and published recently by our team. The first model is a layout analysis model, an accurate object-detector for page elements [13]. The second model is TableFormer [12, 9], a state-of-the-art table structure re...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/50', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 3, 'bbox': {'l': 108.0, 't': 405.1419982910156, 'r': 504.00299072265625, 'b': 330.7799987792969, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 608]}]}], 'headings': ['3.2 AI models'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 2:\n",
            "  text: \"3 Processing pipeline\\nDocling implements a linear pipeline of operations, which execute sequentially on each given document (see Fig. 1). Each document is first parsed by a PDF backend, which retrieves the programmatic text tokens, consisting of string content and its coordinates on the page, and also renders a bitmap image of each page to support ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/26', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 2, 'bbox': {'l': 108.0, 't': 273.01800537109375, 'r': 504.00299072265625, 'b': 176.83799743652344, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 796]}]}], 'headings': ['3 Processing pipeline'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n",
            "\n",
            "Source 3:\n",
            "  text: \"6 Future work and contributions\\nDocling is designed to allow easy extension of the model library and pipelines. In the future, we plan to extend Docling with several more models, such as a figure-classifier model, an equationrecognition model, a code-recognition model and more. This will help improve the quality of conversion for specific types of ...\"\n",
            "  dl_meta: {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/76', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 322.468994140625, 'r': 504.00299072265625, 'b': 259.0169982910156, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 543]}]}, {'self_ref': '#/texts/77', 'parent': {'$ref': '#/body'}, 'children': [], 'label': 'text', 'prov': [{'page_no': 5, 'bbox': {'l': 108.0, 't': 251.6540069580078, 'r': 504.00299072265625, 'b': 198.99200439453125, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 402]}]}], 'headings': ['6 Future work and contributions'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 11465328351749295394, 'filename': '2408.09869v5.pdf'}}\n",
            "  source: https://arxiv.org/pdf/2408.09869\n"
          ]
        }
      ],
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "resp_dict = rag_chain.invoke({\"input\": QUESTION})\n",
        "\n",
        "clipped_answer = clip_text(resp_dict[\"answer\"], threshold=350)\n",
        "print(f\"Question:\\n{resp_dict['input']}\\n\\nAnswer:\\n{clipped_answer}\")\n",
        "for i, doc in enumerate(resp_dict[\"context\"]):\n",
        "    print()\n",
        "    print(f\"Source {i + 1}:\")\n",
        "    print(f\"  text: {json.dumps(clip_text(doc.page_content, threshold=350))}\")\n",
        "    for key in doc.metadata:\n",
        "        if key != \"pk\":\n",
        "            val = doc.metadata.get(key)\n",
        "            clipped_val = clip_text(val) if isinstance(val, str) else val\n",
        "            print(f\"  {key}: {clipped_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNoCunpO1qlQ"
      },
      "source": [
        "Notice that the sources contain rich grounding information, including the passage\n",
        "headings (i.e. section), page, and precise bounding box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlZ7RQwd1qlQ"
      },
      "source": [
        "## API reference\n",
        "\n",
        "- [LangChain Docling integration GitHub](https://github.com/docling-project/docling-langchain)\n",
        "- [Docling GitHub](https://github.com/docling-project/docling)\n",
        "- [Docling docs](https://docling-project.github.io/docling//)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J1NBYYQ1qlQ"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}